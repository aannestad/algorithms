{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def editDistance(str1, str2, m, n):\n",
    "\n",
    "\tif m == 0:\n",
    "\t\treturn n\n",
    "\n",
    "\tif n == 0:\n",
    "\t\treturn m\n",
    "\n",
    "\tif str1[m-1] == str2[n-1]:\n",
    "\t\treturn editDistance(str1, str2, m-1, n-1)\n",
    "\n",
    "\treturn 1 + min(editDistance(str1, str2, m, n-1), # Insert\n",
    "\t\t\t\teditDistance(str1, str2, m-1, n), # Remove\n",
    "\t\t\t\teditDistance(str1, str2, m-1, n-1) # Replace\n",
    "\t\t\t\t)\n",
    "\n",
    "# This code is contributed by Bhavya Jain, thanks!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=1\n",
      "['where', 'wheel', 'wheee']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 1 -What is the minimum distance (D) from the following word to any of the words in the database and\n",
    "# how many words (N) in the database has the same distance to the word.\n",
    "\n",
    "# Get the data from Donald Knuth\n",
    "\n",
    "link = \"https://www-cs.stanford.edu/~knuth/sgb-words.txt\"\n",
    "f = requests.get(link)\n",
    "text = f.text\n",
    "words = text.split()\n",
    "\n",
    "word = \"whee\"\n",
    "\n",
    "word_dict = dict()\n",
    "\n",
    "for w in words:\n",
    "    word_dict[w] = editDistance(w, word, len(w), len(word))\n",
    "\n",
    "D=min(word_dict.values())\n",
    "print('D=' + str(D))\n",
    "\n",
    "min_dist_words = [k for k,v in word_dict.items() if v==D]\n",
    "print(min_dist_words)\n",
    "print(len(min_dist_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=3\n",
      "['again', 'areas', 'ahead', 'apart', 'aware', 'canal', 'awake', 'altar', 'alarm', 'salad', 'radar', 'array', 'naval', 'algae', 'award', 'fatal', 'atlas', 'madam', 'adapt', 'await', 'cacao', 'nasal', 'pagan', 'carat', 'adage', 'aback', 'allay', 'amaze', 'sagas', 'agate', 'amass', 'lavas', 'assay', 'kayak', 'karat', 'abate', 'mamas', 'squab', 'alias', 'rajah', 'galas', 'papaw', 'papas', 'avail', 'papal', 'alack', 'avant', 'farad', 'basal', 'awash', 'apace', 'axial', 'natal', 'banal', 'agave', 'aways', 'annas', 'abaci', 'arias', 'paean', 'abase', 'aural', 'carob', 'avast', 'axman', 'avian', 'adlib', 'adman', 'auras', 'rehab', 'macaw', 'abash', 'aquas', 'cabal', 'lanai', 'kabob', 'lamas', 'nabob', 'naiad', 'kebab', 'hapax', 'agape', 'alway', 'abaca', 'paras', 'algal', 'areal', 'amahs', 'bazar', 'lulab', 'kraal', 'saran', 'agars', 'aquae', 'aargh', 'arras', 'apian', 'casas', 'japan', 'pavan', 'abeam', 'vocab', 'assai', 'asana', 'sahib', 'attar', 'kaiak', 'rasae', 'aurae', 'abaft', 'rajas']\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "# 2 -What is the minimum distance (D) from the following word to any of the words in the database and\n",
    "# how many words (N) in the database has the same distance to the word.\n",
    "\n",
    "# Get the data from Donald Knuth\n",
    "\n",
    "link = \"https://www-cs.stanford.edu/~knuth/sgb-words.txt\"\n",
    "f = requests.get(link)\n",
    "text = f.text\n",
    "words = text.split()\n",
    "\n",
    "word = \"aaaab\"\n",
    "\n",
    "word_dict = dict()\n",
    "\n",
    "for w in words:\n",
    "    word_dict[w] = editDistance(w, word, len(w), len(word))\n",
    "\n",
    "D=min(word_dict.values())\n",
    "print('D=' + str(D))\n",
    "\n",
    "min_dist_words = [k for k,v in word_dict.items() if v==D]\n",
    "print(min_dist_words)\n",
    "print(len(min_dist_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=1\n",
      "['alpha']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 3 -What is the minimum distance (D) from the following word to any of the words in the database and\n",
    "# how many words (N) in the database has the same distance to the word.\n",
    "\n",
    "# Get the data from Donald Knuth\n",
    "\n",
    "link = \"https://www-cs.stanford.edu/~knuth/sgb-words.txt\"\n",
    "f = requests.get(link)\n",
    "text = f.text\n",
    "words = text.split()\n",
    "\n",
    "word = \"alpga\"\n",
    "\n",
    "word_dict = dict()\n",
    "\n",
    "for w in words:\n",
    "    word_dict[w] = editDistance(w, word, len(w), len(word))\n",
    "\n",
    "D=min(word_dict.values())\n",
    "print('D=' + str(D))\n",
    "\n",
    "min_dist_words = [k for k,v in word_dict.items() if v==D]\n",
    "print(min_dist_words)\n",
    "print(len(min_dist_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=2\n",
      "['mouth', 'south', 'truth', 'youth', 'knots', 'knits', 'knurl', 'knish', 'klutz', 'couth', 'knout']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# 4 -What is the minimum distance (D) from the following word to any of the words in the database and\n",
    "# how many words (N) in the database has the same distance to the word.\n",
    "\n",
    "# Get the data from Donald Knuth\n",
    "\n",
    "link = \"https://www-cs.stanford.edu/~knuth/sgb-words.txt\"\n",
    "f = requests.get(link)\n",
    "text = f.text\n",
    "words = text.split()\n",
    "\n",
    "word = \"knuth\"\n",
    "\n",
    "word_dict = dict()\n",
    "\n",
    "for w in words:\n",
    "    word_dict[w] = editDistance(w, word, len(w), len(word))\n",
    "\n",
    "D=min(word_dict.values())\n",
    "print('D=' + str(D))\n",
    "\n",
    "min_dist_words = [k for k,v in word_dict.items() if v==D]\n",
    "print(min_dist_words)\n",
    "print(len(min_dist_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=4\n",
      "['quite', 'equal', 'quiet', 'quick', 'queen', 'queer', 'quart', 'quilt', 'quote', 'quest', 'quack', 'squad', 'quail', 'quill', 'squat', 'squid', 'quota', 'squaw', 'quake', 'queue', 'equip', 'query', 'quirk', 'quays', 'quits', 'quell', 'squab', 'quaff', 'qualm', 'quips', 'quoth', 'quipu', 'quirt', 'pique', 'quint', 'quire', 'quads', 'squib', 'quasi', 'quash', 'quals', 'aquas', 'quark', 'quais', 'coqui', 'toque', 'quiff', 'aquae', 'deque', 'quids', 'qophs', 'quoin', 'quoit']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# 5 -What is the minimum distance (D) from the following word to any of the words in the database and\n",
    "# how many words (N) in the database has the same distance to the word.\n",
    "\n",
    "# Get the data from Donald Knuth\n",
    "\n",
    "link = \"https://www-cs.stanford.edu/~knuth/sgb-words.txt\"\n",
    "f = requests.get(link)\n",
    "text = f.text\n",
    "words = text.split()\n",
    "\n",
    "word = \"qqqqq\"\n",
    "\n",
    "word_dict = dict()\n",
    "\n",
    "for w in words:\n",
    "    word_dict[w] = editDistance(w, word, len(w), len(word))\n",
    "\n",
    "D=min(word_dict.values())\n",
    "print('D=' + str(D))\n",
    "\n",
    "min_dist_words = [k for k,v in word_dict.items() if v==D]\n",
    "print(min_dist_words)\n",
    "print(len(min_dist_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=3\n",
      "['doing', 'dying', 'sting', 'icing', 'eying', 'edits', 'eking', 'piing']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# 5 -What is the minimum distance (D) from the following word to any of the words in the database and\n",
    "# how many words (N) in the database has the same distance to the word.\n",
    "\n",
    "# Get the data from Donald Knuth\n",
    "\n",
    "link = \"https://www-cs.stanford.edu/~knuth/sgb-words.txt\"\n",
    "f = requests.get(link)\n",
    "text = f.text\n",
    "words = text.split()\n",
    "\n",
    "word = \"editing\"\n",
    "\n",
    "word_dict = dict()\n",
    "\n",
    "for w in words:\n",
    "    word_dict[w] = editDistance(w, word, len(w), len(word))\n",
    "\n",
    "D=min(word_dict.values())\n",
    "print('D=' + str(D))\n",
    "\n",
    "min_dist_words = [k for k,v in word_dict.items() if v==D]\n",
    "print(min_dist_words)\n",
    "print(len(min_dist_words))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4cdbc7c3fa968f8f57a8da50a47c3ee9b8594a4de967130c021b1087ec3a6ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
